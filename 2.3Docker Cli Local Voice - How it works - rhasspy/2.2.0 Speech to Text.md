 asr

The first step of this process is converting speech to text (transcription).

converts PCM audio to text using OpenAI’s Whisper model.

Inputs fixed-sized chunks of PCM audio
Inputs an event indicating the end of the audio stream (or voice command)
Outputs a transcription

 transform speech (WAV) to text. The /api/speech-to-text endpoint from Rhasspy's HTTP API does just this, allowing you to use a remote instance of Rhasspy for speech recognition.

They appear in the debug log:
 ~~~
  - type: stt-start
    data:
      engine: stt.vosk
      metadata:
        language: zh
        format: wav
        codec: pcm
        bit_rate: 16
        sample_rate: 16000
        channel: 1
    timestamp: "2025-03-01T09:29:13.577791+00:00"
  - type: stt-vad-end
    data:
      timestamp: 15000
    timestamp: "2025-03-01T09:29:45.821522+00:00"
  - type: stt-end
    data:
      stt_output:
        text: 真
    timestamp: "2025-03-01T09:29:50.909170+00:00"

 ~~~


 OpenAI’s Whisper

 faster-whisper

 vosk

 funasr

 sherpa asr

Natural Language Processing